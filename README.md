# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
- Project Aim: Develop a binary classification model to determine whether a client will sign up for a term deposit at the bank.
- Dataset: UCI Bank Marketing dataset, which includes client details such as age, job, marital status, and education levels.
- Methods Used:
    - AzureML HyperDrive:
      - Developed 36 LogisticRegression models.
      - Highest-performing model achieved an accuracy of 91%.
    - Microsoft’s AutoML:
      - Top-performing model was a VotingEnsemble.
      - VotingEnsemble model performed slightly better than the best HyperDrive model.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Pipeline Flow chart:
![AutoML_Udacity_Course2_project](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/AutoML%20Udacity%20Course2%20project.jpg)

- `Data`:
  - Data Ingestion: Data ingested using 'Dataset' class using a https-request.
  - Data Preprocessing: Data-Cleaning and converting object-cloumn-features to numericals via One-Hot encoding. Final, target feature was converted to numerical-binary class.
- `Model Training`:
  - Hyper-parameter Tuning: Azure ML's Hyperdrive service for hyperparameter tuning, which is the process of determining the best hyperparameter settings to optimize model performance. We provided Parameter-Sampling and Primary-Metric to optmize for, and find the best model.
  - Logistic Regression Model using HyperDrive | Code: [udacity-project_accuracy_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_accuracy_metric.ipynb)
    - `Accuracy`: 91% Accuracy was achieved with C = 3.566 
    - `F1 Score`: 0.52 F1-Score with C = 1.893
  - AutoML Model via 2 different metrics
    - `Accuracy`: VotingEnsemble with Accuracy of 91% | Code: [udacity-project_accuracy_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_accuracy_metric.ipynb)
    - `AUC_Weighted`: VotingEnsemble with 95% AUC | Code: [udacity-project_AUC_weighted_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_AUC_weighted_metric.ipynb)
   
**What are the benefits of the parameter sampler you chose?**
The parameter sampler used allows us, the adjustment of hyperparameters by testing various combination of values within a specified range for each hyperparameter.
Below is the selection of my hyper-parameters:
- Discrete Options: Selected through the choice method for the parameters C and max_iter.
  - `C`: Represents the Regularization factor.
  - `max_iter`: Signifies the maximum iterations allowed.
- Sampling Method: Chose `RandomParameterSampling` for its speed and ability to halt underperforming runs early.
  - Randomly picks values for hyperparameters from the established range.

**What are the benefits of the early stopping policy you chose?**
The early stopping policy implemented, terminates runs prematurely based on their performance against the primary metric, effectively identifying and stopping low-performing runs to save time and resources.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The AutoML process involved many different executions, employing various algorithms and hyperparameters. 
The most successful execution produced a **`VotingEnsemble`** model, which utilized a combination of hyperparameters including algorithms such as:
`['LightGBM', 'XGBoostClassifier', 'XGBoostClassifier', 'XGBoostClassifier', 'LightGBM', 'XGBoostClassifier', 'LogisticRegression', 'SGD']`

https://github.com/user-attachments/assets/e61e3540-dc53-4086-8605-06494ae958b2


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The overall performance of the models were similar, with the VotingEnsemble model produced using AutoML showing only a slight improvement of 0.83 in accuracy compared to the Logistic Regression model trained with HyperDrive.
- LogisticRegression Accuracy: 0.91
- AutomML VotingEnsemble Accuracy: 0.9183

#### AutoML result
26 VotingEnsemble 0:01:06 0.9183 0.9183

#### Hyperdrive result
Best Run Id:  HD_ba10dfd2-d83f-4c8d-a845-c6e8ff8ab550_7
Accuracy: 0.9147192716236723
['--C', '3.566313318702827', '--max_iter', '100']

**C is the Regularization while max_iter is the maximum number of iterations.**

#### Reasons for Performance Differences
- `Model Complexity and Diversity`
- `Hyperparameter Tuning and Model Optimization`
    - `AutoML`: Automatically experiments with many different models and hyperparameters
    - `HyperDrive`: Focuses on optimizing the hyperparameters of a single model (logistic regression in this case)

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
- Improve imbalance with other algorithm
  - An example run was performed with `class_weight='balanced'` parameter to Logistic Regression in `train.py`. The Accuracy achieved was around 87%
  - Further experiments can be performed using AutoML power.
- Advacned `Feature-Engineering.`

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
Performed the cleanup using `clsuter.delete` in notebook: [udacity-project_AUC_weighted_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_AUC_weighted_metric.ipynb)

***
## Suggestions to Make Your Project Stand Out
1. Include a diagram of your pipeline architecture. ✅
2. Export your model and run it in Cloud Shell. In-Progress ⏳
3. Extend your AutoML config to include more parameters. ✅
4. Have your code check for existing compute clusters before creating a new one. ✅
