# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
- Project Aim: Develop a binary classification model to determine whether a client will sign up for a term deposit at the bank.
- Dataset: UCI Bank Marketing dataset, which includes client details such as age, job, marital status, and education levels.
- Methods Used:
    - AzureML HyperDrive:
      - Developed 36 LogisticRegression models.
      - Highest-performing model achieved an accuracy of 91%.
    - Microsoftâ€™s AutoML:
      - Top-performing model was a VotingEnsemble.
      - VotingEnsemble model performed slightly better than the best HyperDrive model.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Pipeline Flow chart:
![AutoML_Udacity_Course2_project](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/AutoML%20Udacity%20Course2%20project.jpg)

- `Data`:
  - Data Ingestion: Data ingested using 'Dataset' class using a https-request.
  - Data Preprocessing: Data-Cleaning and converting object-cloumn-features to numericals via One-Hot encoding. Final, target feature was converted to numerical-binary class.
- `Model Training`:
  - Hyper-parameter Tuning: Azure ML's Hyperdrive service for hyperparameter tuning, which is the process of determining the best hyperparameter settings to optimize model performance. We provided Parameter-Sampling and Primary-Metric to optmize for, and find the best model.
  - Logistic Regression Model using HyperDrive | Code: [udacity-project_accuracy_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_accuracy_metric.ipynb)
    - `Accuracy`: 91% Accuracy was achieved with C = 3.566 
    - `F1 Score`: 0.52 F1-Score with C = 1.893
  - AutoML Model via 2 different metrics
    - `Accuracy`: VotingEnsemble with Accuracy of 91% | Code: [udacity-project_accuracy_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_accuracy_metric.ipynb)
    - `AUC_Weighted`: VotingEnsemble with 95% AUC | Code: [udacity-project_AUC_weighted_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_AUC_weighted_metric.ipynb)
   
**What are the benefits of the parameter sampler you chose?**
The parameter sampler used allows us, the adjustment of hyperparameters by testing various combination of values within a specified range for each hyperparameter.
Below is the selection of my hyper-parameters:
- Discrete Options: Selected through the choice method for the parameters C and max_iter.
  - `C`: Represents the Regularization factor.
  - `max_iter`: Signifies the maximum iterations allowed.
- Sampling Method: Chose `RandomParameterSampling` for its speed and ability to halt underperforming runs early.
  - Randomly picks values for hyperparameters from the established range.

**What are the benefits of the early stopping policy you chose?**
The early stopping policy implemented, terminates runs prematurely based on their performance against the primary metric, effectively identifying and stopping low-performing runs to save time and resources.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
- Improve imbalance with other algorithm
  - An example run was performed with `class_weight='balanced'` parameter to Logistic Regression in `train.py`. The Accuracy achieved was around 87%
  - Further experiments can be performed using AutoML power.
- Advacned `Feature-Engineering.`

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
Performed the cleanup using `clsuter.delete` in notebook: [udacity-project_AUC_weighted_metric](https://github.com/mishra-atul5001/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/udacity-project_AUC_weighted_metric.ipynb)

